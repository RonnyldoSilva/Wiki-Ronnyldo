
# Entendendo Attention e Dropout no BERT e Vision Transformer (ViT)

## ğŸ”¹ 1. Attention (AtenÃ§Ã£o)

### ğŸ‘‰ O que Ã©?
O mecanismo de **atenÃ§Ã£o** Ã© o nÃºcleo dos modelos Transformer. Ele permite que o modelo foque em partes relevantes da entrada ao processar um elemento, como uma palavra (no BERT) ou um patch de imagem (no ViT).

### ğŸ“Œ Como funciona?
Cada token ou patch Ã© transformado em trÃªs vetores:

- **Q (Query)**
- **K (Key)**
- **V (Value)**

A atenÃ§Ã£o Ã© calculada com a fÃ³rmula:

\[
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\]

Isso permite ao modelo aprender **quais partes da entrada sÃ£o mais relevantes para cada posiÃ§Ã£o**.

### ğŸ” Exemplos:

- **BERT**: ao analisar a palavra "banco", pode focar na palavra "dinheiro" para entender que se refere a uma instituiÃ§Ã£o financeira.
- **ViT**: ao processar um patch da imagem, pode focar em outros patches com padrÃµes semelhantes.

---

## ğŸ”¹ 2. Dropout

### ğŸ‘‰ O que Ã©?
**Dropout** Ã© uma tÃ©cnica de **regularizaÃ§Ã£o** que ajuda a prevenir o **overfitting**.

### ğŸ“Œ Como funciona?
Durante o **treinamento**, o Dropout **zera aleatoriamente uma porcentagem dos neurÃ´nios** em uma camada.

Isso obriga o modelo a aprender padrÃµes mais robustos, ao invÃ©s de depender de caminhos especÃ­ficos na rede.

### ğŸ“ No contexto do BERT e ViT:

- Dropout Ã© aplicado **apÃ³s a atenÃ§Ã£o** e em outras partes da arquitetura (como o feed-forward).
- Dropout Ã© **desligado durante a inferÃªncia** (avaliaÃ§Ã£o ou produÃ§Ã£o).

---

## ğŸ§  Estrutura Comparativa: BERT vs Vision Transformer

| Componente         | BERT                            | Vision Transformer (ViT)          |
|--------------------|----------------------------------|-----------------------------------|
| Entrada            | Tokens de texto                 | Patches de imagem                 |
| Embeddings         | Word + Positional Embeddings    | Patch + Positional Embeddings     |
| AtenÃ§Ã£o            | Self-Attention                  | Self-Attention                    |
| Dropout            | ApÃ³s atenÃ§Ã£o e FFN              | ApÃ³s atenÃ§Ã£o e FFN                |

---

## âœ… Resumo

| Termo       | FunÃ§Ã£o principal                                                   |
|-------------|---------------------------------------------------------------------|
| Attention   | Permitir o modelo focar nas partes mais relevantes da entrada      |
| Dropout     | Reduzir overfitting apagando neurÃ´nios aleatoriamente no treino    |

---

## ğŸ“Š VisualizaÃ§Ã£o da AtenÃ§Ã£o (Exemplo Simples)

### ğŸ”  Texto (BERT)

Frase: **"O gato estÃ¡ no telhado"**

Suponha que ao analisar "telhado", o modelo preste mais atenÃ§Ã£o em "estÃ¡" e "gato":

```
Palavra:   O   gato  estÃ¡   no  telhado
AtenÃ§Ã£o:   â–‘   â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆ    â–‘      â–ˆâ–ˆ
```

### ğŸ–¼ï¸ Imagem (ViT)

Uma imagem Ã© dividida em **patches** e cada patch pode focar em outros relevantes:

```
Patch 1 â–“â–’â–‘
Patch 2 â–ˆâ–ˆâ–ˆ  <--- Foco principal
Patch 3 â–‘â–‘â–’
...
```

